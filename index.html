<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Seungyeon Kim</title>

  <meta name="author" content="Seungyeon Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css"
    integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    td {
      line-height: 135%;
    }
  </style>

  <link rel="icon" type="image/png" href="images/pushing.jpg">
</head>

<body>
  <table
    style="width:100%;max-width:760px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- <hr color="#c7c7c7" size="0.7" style="width:96%"> -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:5%;width:38%;max-width:38%">
                  <img style="width:100%;max-width:100%" alt="profile photo" src="images/sykim.png"
                    class="hoverZoomLink">
                </td>
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Seungyeon Kim</name>
                  </p>
                  <p>
                    Hello! I am postdoctoral researcher at <a href="http://robot.snu.ac.kr">Robotics Laboratory</a> in Seoul National University, 
                    advised by <a href="https://scholar.google.com/citations?user=u-h3PJIAAAAJ&hl=ko&oi=ao">Frank C. Park</a>. 
                  </p>
                  <p>
                    Prior to joining postdoctoral program, I completed my Ph. D., M.S., and B.S. with Mechanical Engineering (minor: Economics) from
                    Seoul National University.
                  </p>
                  <p>
                    Email: ksy at robotics.snu.ac.kr
                  </p>
                  <p style="text-align:center">
                    <i class="fa fa-file-text"></i><a href="pdfs/CV.pdf"> CV </a> &nbsp&nbsp/&nbsp
                    <i class="fa fa-graduation-cap"></i><a href="https://scholar.google.com/citations?hl=en&user=jNz4SZgAAAAJ"> Google Scholar</a> &nbsp&nbsp/&nbsp
                    <i class="fa fa-github" aria-hidden="true"></i><a href="https://github.com/seungyeon-k"> Github</a> &nbsp&nbsp/&nbsp
                    <i class="fa fa-youtube-play" aria-hidden="true"></i><a href="https://www.youtube.com/@SeungyeonKim-y4v"> Youtube</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <hr color="#c7c7c7" size="0.7" style="width:96%">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  (<a href="pdfs/research_statement.pdf">Research Statement</a>)
                  <p style="padding-top:5px">
                    My research focuses on developing practical solutions for intelligent robots that are adaptive and generalizable to 
                    unknown arbitrary environments. I am particularly interested in leveraging <b>inductive biases</b> to enable
                    robots to perform effectively in real-world scenarios with limited data while also adapting to various 
                    downstream manipulation tasks. My research aims to address the challenges of designing effective inductive biases for intelligent
                    robots and contribute to the development of more efficient and capable robotic systems.

                  </p>

                  <ul>
                    <li> 
                      Introducing inductive bias into the <b>recognition system</b> enables efficient 3D reconstruction of objects 
                      from partial and incomplete visual observations, allowing robots to manipulate them effectively
                      [<a href="https://dsqnet.github.io/">T-ASE 2022</a>,
                      <a href="https://searchforgrasp.github.io/">CoRL 2023</a>,
                      <a href="https://t2sqnet.github.io/">CoRL 2024</a>,
                      <a href="https://screwsplat.github.io/">CoRL 2025</a>].
                    </li>
                    <li>
                      Adopting <b>equivariant models</b> reduces data requirements while enhancing generalizability across diverse robot manipulation tasks, 
                      ranging from pushing dynamics learning to skill learning
                      [<a href="https://sqpdnet.github.io/">CoRL 2022</a>,
                      <a href="https://equimmp.github.io/">CoRL 2023</a>].
                    </li>
                    <li> 
                      Identifying <b>low-dimensional representations</b> of robot trajectories reduces the complexity of high-dimensional data, 
                      enabling rapid adaptation to environmental changes
                      [<a href="https://equimmp.github.io/">CoRL 2023</a>,
                      <a href="https://diverse-policy.github.io/">RA-L 2025</a>,
                      <a href="https://mmflowp.github.io/">RA-L 2025</a>].
                    </li>
                  </ul>

                </td>

              </tr>
            </tbody>
          </table>


          <hr color="#c7c7c7" size="0.7" style="width:96%">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                  <a> <font color="#000000">( * denotes equal contribution.)</font></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/screwsplat_end_2025.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>ScrewSplat: An End-to-End Method for Articulated Object Recognition</papertitle>
                  <br>
                  <strong>Seungyeon Kim</strong>, Junsu Ha, Young Hun Kim, Yonghyeon Lee, Frank C. Park
                  <br>
                  <em>Conference on Robot Learning (CoRL) 2025 </em>
                  <br>
                  <b>
                    <font color="#C11B17">Oral Presentation</font>
                  </b> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://screwsplat.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/pdf/2508.02146v1">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/ScrewSplat-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/screwsplat_end_2025.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/dreamgrasp_zero_2025.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation</papertitle>
                  <br>
                  Young Hun Kim, <strong>Seungyeon Kim</strong>, Yonghyeon Lee, Frank C. Park
                  <br>
                  <em>arXiv 2025 </em>
                  <br>
                  <a href="https://dreamgrasp.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/pdf/2507.05627">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/dreamgrasp_zero_2025.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/motion_manifold_2025.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Motion Manifold Flow Primitives for Task-Conditioned Trajectory Generation under Complex Task-Motion Dependencies</papertitle>
                  <br>
                  Yonghyeon Lee, Byeongho Lee, <strong>Seungyeon Kim</strong>, Frank C. Park
                  <br>
                  <em>IEEE Robotics and Automation Letters (RA-L) 2025 </em>
                  <br>
                  <a href="https://mmflowp.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2407.19681">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/motion_manifold_2025.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/diverse_policy_2025.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Diverse Policy Learning via Random Obstacle Deployment for Zero-Shot Adaptation</papertitle>
                  <br>
                  Seokjin Choi*, Yonghyeon Lee*, <strong>Seungyeon Kim</strong>, Che-Sang Park, Himchan Hwang, Frank C. Park
                  <br>
                  <em>IEEE Robotics and Automation Letters (RA-L) 2025 </em>
                  <br>
                  <a href="https://diverse-policy.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/10847909">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/ChoiSeokJin/DIVO">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/diverse_policy_2025.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/t2sqnet_recognition_2024.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>T<sup>2</sup>SQNet: A Recognition Model for Manipulating Partially Observed Transparent Tableware Objects</papertitle>
                  <br>
                  Young Hun Kim*, <strong>Seungyeon Kim*</strong>, Yonghyeon Lee, Frank C. Park
                  <br>
                  <em>Conference on Robot Learning (CoRL) 2024 </em>
                  <br>
                  <a href="https://t2sqnet.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://raw.githubusercontent.com/mlresearch/v270/main/assets/kim25d/kim25d.pdf">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/T2SQNet-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/t2sqnet_recognition_2024.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/leveraging_3d_2023.gif" alt="ms" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:1px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Leveraging 3D Reconstruction for Mechanical Search on Cluttered Shelves</papertitle>
                  <br>
                  <strong>Seungyeon Kim*</strong>, Young Hun Kim*, Yonghyeon Lee, Frank C. Park
                  <br>
                  <em>Conference on Robot Learning (CoRL) 2023 </em>
                  <br>
                  <a href="https://searchforgrasp.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://proceedings.mlr.press/v229/kim23a/kim23a.pdf">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/Search-for-Grasp-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/leveraging_3d_2023.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/equivariant_motion_2023.gif" alt="emmp" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:3px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Equivariant Motion Manifold Primitives</papertitle>
                  <br>
                  Byeongho Lee*, Yonghyeon Lee*, <strong>Seungyeon Kim</strong>, MinJun Son, Frank C. Park
                  <br>
                  <em>Conference on Robot Learning (CoRL) 2023 </em>
                  <br>
                  <a href="https://equimmp.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://proceedings.mlr.press/v229/lee23a/lee23a.pdf">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/dlsfldl/EMMP-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/equivariant_motion_2023.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/se2_manipulations_2022.gif" alt="se2" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:3px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>SE(2)-Equivariant Pushing Dynamics Models for Tabletop Object Manipulations</papertitle>
                  <br>
                  <strong>Seungyeon Kim</strong>, Byeongdo Lim, Yonghyeon Lee, Frank C. Park
                  <br>
                  <em>Conference on Robot Learning (CoRL) 2022 </em>
                  <br>
                  <b>
                    <font color="#C11B17">Oral Presentation</font>
                  </b> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://sqpdnet.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://proceedings.mlr.press/v205/kim23b/kim23b.pdf">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/SQPDNet-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://proceedings.mlr.press/v205/kim23b/kim23b-supp.pdf">Supplementary</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/se2_manipulations_2022.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/dsqnet_objects_2022.gif" alt="dsqnet" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>DSQNet: A Deformable Model-Based Supervised Learning Algorithm for Grasping Unknown Occluded Objects</papertitle>
                  <br>
                  <strong>Seungyeon Kim*</strong>, Taegyun Ahn*, Yonghyeon Lee, Jihwan Kim, Michael Y. Wang, Frank C. Park
                  <br>
                  <em>IEEE Transactions on Automation Science and Engineering (T-ASE) 2022 </em>
                  <br>
                  <a href="https://dsqnet.github.io/">Project Page</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://ieeexplore.ieee.org/abstract/document/9802912?casa_token=DDg8CXt8Z2gAAAAA:sYnwNn9vX2Vl7Y1p68zkqSuPKvYbKX8q8lJgae29uXXt05PcVjU78GI127Knz1X888rv85l-4Q">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/DSQNet-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/dsqnet_objects_2022.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/statistical_data_2022.gif" alt="smf" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:5px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>A Statistical Manifold Framework for Point Cloud Data</papertitle>
                  <br>
                  Yonghyeon Lee*, <strong>Seungyeon Kim*</strong>, Jinwon Choi, Frank C. Park
                  <br>
                  <em>International Conference on Machine Learning (ICML) 2022 </em>
                  <br>
                  <a href="https://proceedings.mlr.press/v162/lee22d/lee22d.pdf">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="https://github.com/seungyeon-k/SMF-public">Code</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/statistical_data_2022.txt">Bibtex</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/encoding_adaptation_2021.gif" alt="jnp" width="160" style="margin-top: 5px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>On the Encoding Capacity of Human Motor Adaptation</papertitle>
                  <br>
                  <strong>Seungyeon Kim</strong>, Jaewoon Kwon, Jin-Min Kim, Frank C. Park, Sang-Hoon Yeo
                  <br>
                  <em>Journal of Neurophysiology (JNP) 2021</em>
                  <br>
                  <a href="https://journals.physiology.org/doi/epdf/10.1152/jn.00593.2020">Paper</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                  <a href="bibtex/encoding_adaptation_2021.txt">Bibtex</a>
                </td>
              </tr>
            </tbody>
          </table>

          <hr color="#c7c7c7" size="0.7" style="width:96%">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:0px;padding-bottom:2px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/sr_grasping.gif" alt="sr" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Object Grasping and Manipulation Skills for Stable Housekeeping Service</papertitle>
                  <br>
                  <em>Project Leader </em>
                  <br>
                  The goal of the project is to develop skills to enable various household tasks, specifically, 
                  to develop a skill that can grasp various tableware and objects on the table.
                  <br>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/lane_detection.gif" alt="lane" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Deep Learning-based Lane Detection Algorithm from LiDAR data</papertitle>
                  <br>
                  <em>Project Leader</em>
                  <br>
                  The goal of the proejct to develop a neural network architecture that recognizes 3D lane 
                  information from LiDAR data (3D point cloud + point-wise intensity).
                  <br>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/deep_rl.gif" alt="drl" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Deep Reinforcement Learning Algorithm for Industrial Robot</papertitle>
                  <br>
                  <em>Project Leader </em>
                  <br>
                  The goal of the proejct is to develop safe and efficient reinforcement learning algorithm for 
                  high-gain position controller-based industrial robots.
                  <br>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <center>
                    <img src="images/robot_painting.gif" alt="se2" width="160" style="margin-bottom: 8px">
                  </center>
                </td>
                <td style="padding-left:20px;padding-top:8px;padding-bottom:8px;width:75%;vertical-align:middle">
                  <papertitle>Artificial Intelligence-based Automated Painting Robot System</papertitle>
                  <br>
                  <em>Project Member (Role: Visualization)</em>
                  <br>
                  The goal of the project is to develop an artificial intelligence-based smart painting robot 
                  automation system for automobile factories.
                  <br>
                  <p></p>
                </td>
              </tr>

            </tbody>
          </table>

          <hr color="#c7c7c7" size="0.7" style="width:96%">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Education</heading>
                  <br>
                  <br>
                  <!-- <li><b>Sep 2021 - April 2024.</b> Student researcher at Institute of Advanced Machines and Design </li>
                    <ul>
                      <li>Working in Intelligent Machine System Research Department</li>
                    </ul> -->
                  <li><b>Feb 2024.</b> Ph.D. degree in Mechanical Engineering, Seoul National University </li>
                    <ul>
                      <li>Advisor: Prof. Frank Chongwoo Park</li>
                      <li>Thesis: <b>Learning for Vision-Based Object Manipulation: A Shape Recognition-Based Approach</b><br> &emsp;&nbsp;
                        <a href="pdfs/thesis.pdf">PDF</a> &nbsp;&nbsp;&bull;&nbsp;&nbsp;
                        <a href="pdfs/slides.pdf">Slides</a></li>   
                      <li><b><font color="#C11B17">Outstanding Doctoral Dissertation Award</font></b></li>

                    </ul>
                  <li><b>Feb 2019.</b> M.S. degree in Mechanical Engineering, Seoul National University </li>
                    <ul>
                      <li>Advisor: Prof. Frank Chongwoo Park / work closely with Prof. <a href="https://scholar.google.com/citations?user=ru_z3mMAAAAJ&hl=ko&oi=ao">Sang-Hoon Yeo</a></li>
                      <li>Thesis: <b>On the Encoding Capacity of Human Motor Adaptation</b></li>
                    </ul>
                  <li><b>Feb 2017. </b> B.S. degree in Mechanical Engineering and Minor in Economics, Seoul National University </li>
                    <ul>
                      <li>Summa Cum Laude</li>
                    </ul>
                  <li><b>Feb 2013.</b> Gyeonggibuk Science High School </li>
                  <ul>
                    <li>One-year early graduation</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>


          <hr color="#c7c7c7" size="0.7" style="width:96%">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Teaching Experiences</heading>
                  <br>
                  <br>
                  <li>Teaching Assistant, <b>Geometric Methods for High-Dimensional Data Analysis</b> (M3239.006800), SNU, 2022F </li>
                  <li>Teaching Assistant, <b>Dynamics</b> (446.204A), SNU, 2018F </li>
                  <li>Teaching Assistant, <b>Introduction to Robotics</b> (M2794.0027), SNU, 2017S </li>
                  <li>Undergraduate Student Instructor, <b>Basic Calculus 1</b> (033.016), SNU, 2015S </li>
                  <li>Undergraduate Student Instructor, <b>Basic Calculus 2</b> (033.017), SNU, 2014F </li>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template based on <a href="https://jonbarron.info/">Jon Barron's website</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
  </table>
</body>

</html>